{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats vs Dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen es en realidad un conjunto de píxeles. El objetivo es convertir esos píxeles en un arreglo.\n",
    "Para eso utilizamos cv2 (OpenCV-Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las imagenes se encuentran en la carpeta \"data\" y cumplen con el formato \"categoria.numero.formato\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la categoria es igual nombre indicado, entonces es 1. De otra forma es 0 (indica que pertenece a la otra categoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert = lambda category : int(category == 'dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una funcion para crear nuestro arreglo con las imágenes preprocesadas (X) y nuestro arreglo de labels (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data(path):\n",
    "    for p in os.listdir(path):\n",
    "        #Obtenemos la categoria del nombre del archivo\n",
    "        category = p.split(\".\")[0]\n",
    "        category = convert(category)\n",
    "        \n",
    "        #Leemos la imagen en escala de grises y convertimos los pixeles en un arreglo\n",
    "        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        #Disminuimos el tamaño de la imagen\n",
    "        new_img_array = cv2.resize(img_array, dsize=(100, 100))\n",
    "        \n",
    "        X.append(new_img_array)\n",
    "        y.append(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamar a la funcion create_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_test_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear numpy arrays. Se hace reshape en X para que la forma de nuestros datos cumpla con los requisitos del parámetro \"input_shape\" en Conv2D (x_shape, y_shape, channels). La nueva dimensión es (número de imágenes, 100, 100, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1,100,100,1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar los datos: Los datos en X son valores que varian entre 0 y 255. Esto es porque cada pixel tiene una densidad disntinta de blanco y negro. Esto puede dificultar el aprendizaje del modelo. Para solucionarlo normalizamos los datos. Como sabemos que varian entre 0 y 255, podemos dividir por 255 y obtener valores entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos train_test_split para dividir en conjunto de entrenamiento y conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el modelo Sequential de Keras donde se agrega de a una capa a la vez.\n",
    "\n",
    "* La primera capa es la de convolución (Conv2D). En ella los parámetros que especificamos son:\n",
    "    1. Número de filtros: 32\n",
    "    2. Kernel_size: (3,3)\n",
    "    3. Función de activación: Elegimos Relu\n",
    "    4. Input_shape: (height, width, depth)\n",
    "    \n",
    "   \n",
    "* La segunda capa es la de Pooling. Esta se utiliza para reducir el costo computacional y, hasta cierto punto, también reduce el overfitting.\n",
    "\n",
    "* Luego agregamos otros conjuntos de capas de convolución y pooling con mayor cantidad de filtros.\n",
    "\n",
    "* Agregamos la capa Flatten, la cual convierte los datos en una matriz unidimensional para ingresarlos en la siguiente capa.\n",
    "\n",
    "* Agregamos la capa Dense (Fully connected neural network layer).\n",
    "\n",
    "* Finalmente agregamos otra capa Dense, la cual tiene como output la predicción. Ponemos a la función sigmoide como función de activación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3), activation = 'relu', input_shape = X_train.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(128,(3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(256,(3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parámetros al compilar:\n",
    "\n",
    "* optimizer: Elegimos el algoritmo adam, pero se pueden utilizar otros como SGD o RMSprop.\n",
    "* loss: Debido a que tenemos dos posibles resultados, utilizamos binary_crossentropy.\n",
    "* metrics: Métrica para medir el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 98, 98, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 47, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 2,486,017\n",
      "Trainable params: 2,486,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Parámetros:\n",
    "\n",
    "    Epochs: Cuantas veces el modelo pasa por el conjunto de entrenamiento.\n",
    "    Batch size: La cantidad de datos a la vez que se desea pasar por el modelo.\n",
    "    validation_split: Se encarga de separar conjunto de entrenamiento y de validacion automaticamente (en este caso 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 175s 350ms/step - loss: 0.6569 - accuracy: 0.6012 - val_loss: 0.6081 - val_accuracy: 0.6785\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 174s 348ms/step - loss: 0.5459 - accuracy: 0.7226 - val_loss: 0.5044 - val_accuracy: 0.7515\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 173s 347ms/step - loss: 0.4547 - accuracy: 0.7822 - val_loss: 0.4281 - val_accuracy: 0.7937\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 173s 347ms/step - loss: 0.3803 - accuracy: 0.8266 - val_loss: 0.3930 - val_accuracy: 0.8245\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 174s 348ms/step - loss: 0.3233 - accuracy: 0.8597 - val_loss: 0.3692 - val_accuracy: 0.8460\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 168s 336ms/step - loss: 0.2744 - accuracy: 0.8844 - val_loss: 0.3866 - val_accuracy: 0.8378\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 167s 334ms/step - loss: 0.2238 - accuracy: 0.9082 - val_loss: 0.3849 - val_accuracy: 0.8410\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 167s 333ms/step - loss: 0.1741 - accuracy: 0.9276 - val_loss: 0.4491 - val_accuracy: 0.8353\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 170s 340ms/step - loss: 0.1318 - accuracy: 0.9462 - val_loss: 0.4617 - val_accuracy: 0.8443\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 167s 334ms/step - loss: 0.1060 - accuracy: 0.9574 - val_loss: 0.4905 - val_accuracy: 0.8540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17c53539d90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redondeamos los valores ya que usamos la función sigmoide y obtuvimos los valores de probabilidad en nuestras predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_y_pred():\n",
    "    for p in predictions:\n",
    "        p = p.round()\n",
    "        y_pred.append(p)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_y_pred()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos scikit para realizar el reporte de clasificación, el cual nos muestra la precisión, recall y f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      2507\n",
      "           1       0.86      0.84      0.85      2493\n",
      "\n",
      "    accuracy                           0.85      5000\n",
      "   macro avg       0.85      0.85      0.85      5000\n",
      "weighted avg       0.85      0.85      0.85      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la matriz de confusión y la imprimimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2167,  340],\n",
       "       [ 399, 2094]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para plotear la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)   \n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "cm_plot_labels = ['cat','dog']   \n",
    "plot_confusion_matrix(cm=c_matrix, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_data = \"data/test1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "image_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unlabeled_data(path):\n",
    "    for p in os.listdir(path):\n",
    "        image_name.append(p)\n",
    "        #Leemos la imagen en escala de grises y convertimos los pixeles en un arreglo\n",
    "        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)        \n",
    "        #Disminuimos el tamaño de la imagen\n",
    "        new_img_array = cv2.resize(img_array, dsize=(100, 100))        \n",
    "        X.append(new_img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_unlabeled_data(path_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos numpy arrays\n",
    "X_test = np.array(X).reshape(-1,100,100,1)\n",
    "\n",
    "#Normalizamos\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El razonamiento es el siguiente: Mientras el resultado de predictions sea mas cercano a 0, entonces es cat. Mientras sea mas cercano a 1, es dog. Si la red no está lo suficientemente segura, entonces lo clasificamos como otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_percetenges():\n",
    "    for p in predictions:\n",
    "        #print(p)\n",
    "        if p > 0.35  and p < 0.80:\n",
    "            p = [2.0] \n",
    "        else:\n",
    "            p = p.round()\n",
    "            \n",
    "        y_pred.append(p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "round_percetenges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los resultados (0 = Cat, 1 = Dog, 2 = Other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen: 1.jpg - Prediccion: Cat   -Porcentaje 0.09946391 %\n",
      "Imagen: 10.jpg - Prediccion: Cat   -Porcentaje 2.156303e-06 %\n",
      "Imagen: 100.jpg - Prediccion: Cat   -Porcentaje 0.060059875 %\n",
      "Imagen: 1000.jpg - Prediccion: Dog  -Porcentaje 0.99809885 %\n",
      "Imagen: 10000.jpg - Prediccion: Dog  -Porcentaje 0.99438155 %\n",
      "Imagen: 10001.jpg - Prediccion: Cat   -Porcentaje 0.0031434596 %\n",
      "Imagen: 10002.jpg - Prediccion: Cat   -Porcentaje 0.01936227 %\n",
      "Imagen: 10003.jpg - Prediccion: Dog  -Porcentaje 0.99990684 %\n",
      "Imagen: 10004.jpg - Prediccion: Dog  -Porcentaje 0.9809032 %\n",
      "Imagen: 10005.jpg - Prediccion: Cat   -Porcentaje 3.268776e-08 %\n"
     ]
    }
   ],
   "source": [
    "#for i in range(len(y_pred)):\n",
    "#Imprimimos los primeros 10 como prueba\n",
    "for i in range(10):\n",
    "    #print(\"Imagen:\" , image_name[i] , \"- Prediccion:\" , y_pred[i][0], \"   -Porcentaje\", predictions[i][0], \"%\")\n",
    "    if y_pred[i][0] == 0.0:\n",
    "        print(\"Imagen:\" , image_name[i] , \"- Prediccion: Cat   -Porcentaje\", predictions[i][0], \"%\")\n",
    "    elif y_pred[i][0] == 1.0:\n",
    "        print(\"Imagen:\" , image_name[i] , \"- Prediccion: Dog  -Porcentaje\", predictions[i][0], \"%\")\n",
    "    else:\n",
    "        print(\"Imagen:\" , image_name[i] , \"- Prediccion: Other -Porcentaje\", predictions[i][0], \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
